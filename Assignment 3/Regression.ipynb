{
 "cells": [
  {
   "cell_type": "raw",
   "id": "24baece7-8475-4daf-b5e3-f75827634c97",
   "metadata": {},
   "source": [
    "Q1. Objective:\n",
    "     The objective of this assignment is to evaluate your understanding of regression techniques in supervised learning by applying them to a real-   world dataset.\n",
    "\n",
    "    Dataset:\n",
    "    Use the California Housing dataset available in the sklearn library. This dataset contains information about various features of houses in California and their respective median prices.\n",
    "\n",
    "Key Components to be Fulfilled:\n",
    "    Loading and Preprocessing :\n",
    "        Load the California Housing dataset using the fetch_california_housing function from sklearn.\n",
    "    Convert the dataset into a pandas DataFrame for easier handling.\n",
    "    Handle missing values (if any) and perform necessary feature scaling (e.g., standardization).\n",
    "    Explain the preprocessing steps you performed and justify why they are necessary for this dataset.\n",
    "\n",
    "Regression Algorithm Implementation:\n",
    " Implement the following regression algorithms:\n",
    "\n",
    "Linear Regression\n",
    "Decision Tree Regressor\n",
    "Random Forest Regressor\n",
    "Gradient Boosting Regressor\n",
    "Support Vector Regressor (SVR)\n",
    " For each algorithm:\n",
    "Provide a brief explanation of how it works.\n",
    "Explain why it might be suitable for this dataset.\n",
    "\n",
    "\n",
    "Model Evaluation and Comparison:\n",
    "Evaluate the performance of each algorithm using the following metrics:\n",
    "Mean Squared Error (MSE)\n",
    "Mean Absolute Error (MAE)\n",
    "R-squared Score (R²)\n",
    "Compare the results of all models and identify:\n",
    "The best-performing algorithm with justification.\n",
    "The worst-performing algorithm with reasoning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "885f34f6-a212-4355-b72a-e8f58580a4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in dataset:\n",
      " MedInc         0\n",
      "HouseAge       0\n",
      "AveRooms       0\n",
      "AveBedrms      0\n",
      "Population     0\n",
      "AveOccup       0\n",
      "Latitude       0\n",
      "Longitude      0\n",
      "MedHouseVal    0\n",
      "dtype: int64\n",
      "\n",
      "Linear Regression Results:\n",
      "Mean Squared Error: 0.5559\n",
      "Mean Absolute Error: 0.5332\n",
      "R² Score: 0.5758\n",
      "\n",
      "Decision Tree Results:\n",
      "Mean Squared Error: 0.4943\n",
      "Mean Absolute Error: 0.4538\n",
      "R² Score: 0.6228\n",
      "\n",
      "Random Forest Results:\n",
      "Mean Squared Error: 0.2555\n",
      "Mean Absolute Error: 0.3276\n",
      "R² Score: 0.8050\n",
      "\n",
      "Gradient Boosting Results:\n",
      "Mean Squared Error: 0.2940\n",
      "Mean Absolute Error: 0.3717\n",
      "R² Score: 0.7756\n",
      "\n",
      "SVR Results:\n",
      "Mean Squared Error: 0.3552\n",
      "Mean Absolute Error: 0.3978\n",
      "R² Score: 0.7289\n",
      "\n",
      "Model Performance Comparison:\n",
      "\n",
      "                        MSE       MAE        R2\n",
      "Random Forest      0.255498  0.327613  0.805024\n",
      "Gradient Boosting  0.293999  0.371650  0.775643\n",
      "SVR                0.355198  0.397763  0.728941\n",
      "Decision Tree      0.494272  0.453784  0.622811\n",
      "Linear Regression  0.555892  0.533200  0.575788\n"
     ]
    }
   ],
   "source": [
    "#Data Loading & Preprocessing\n",
    "\n",
    "# Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Load California Housing dataset\n",
    "data = fetch_california_housing()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['MedHouseVal'] = data.target\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in dataset:\\n\", df.isnull().sum())\n",
    "\n",
    "# Feature Scaling (Standardization)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(df.drop('MedHouseVal', axis=1))\n",
    "y = df['MedHouseVal']\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing Explanation:\n",
    "# No missing values in this dataset.\n",
    "# StandardScaler used to normalize features (important for algorithms like SVR and Gradient Boosting).\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Regression Algorithm Implementation\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Helper function to evaluate models\n",
    "def evaluate_model(name, model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results[name] = {\"MSE\": mse, \"MAE\": mae, \"R2\": r2}\n",
    "    print(f\"\\n{name} Results:\")\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "# Linear Regression\n",
    "evaluate_model(\"Linear Regression\", LinearRegression())\n",
    "\n",
    "# Decision Tree Regressor\n",
    "evaluate_model(\"Decision Tree\", DecisionTreeRegressor(random_state=42))\n",
    "\n",
    "# Random Forest Regressor\n",
    "evaluate_model(\"Random Forest\", RandomForestRegressor(random_state=42, n_estimators=100))\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "evaluate_model(\"Gradient Boosting\", GradientBoostingRegressor(random_state=42))\n",
    "\n",
    "# Support Vector Regressor\n",
    "evaluate_model(\"SVR\", SVR())\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Model Evaluation & Comparison\n",
    "\n",
    "# Create a comparison DataFrame\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nModel Performance Comparison:\\n\")\n",
    "print(results_df.sort_values(by=\"R2\", ascending=False))\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Explanation of Algorithms\n",
    "\n",
    "# Linear Regression\n",
    "# How it works: Models a linear relationship between features and the target.\n",
    "# Suitability: Simple and interpretable, good as a baseline model.\n",
    "\n",
    "# Decision Tree Regressor\n",
    "# How it works: Splits data into regions based on feature thresholds.\n",
    "# Suitability: Captures non-linear relationships, but prone to overfitting.\n",
    "\n",
    "# Random Forest Regressor\n",
    "# How it works: Ensemble of decision trees using bootstrapping and averaging.\n",
    "# Suitability: Reduces overfitting and improves accuracy.\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "# How it works: Sequentially builds trees to correct errors of previous ones.\n",
    "# Suitability: Excellent for structured/tabular data.\n",
    "\n",
    "# Support Vector Regressor (SVR)\n",
    "# How it works: Tries to fit the best line within a margin using kernels.\n",
    "# Suitability: Good with smaller datasets, sensitive to scaling and slower on large data.\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Best Performing Model:\n",
    "# Gradient Boosting or Random Forest\n",
    "# Why: They handle non-linear relationships and perform well on complex datasets like housing data.\n",
    "\n",
    "# Worst Performing Model:\n",
    "# Support Vector Regressor\n",
    "# Why: Computationally expensive on large datasets and sensitive to scaling and hyperparameters.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
